{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github.com/Fra-Sala/gnn_time/blob/main/notebook/11_lid_cavity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtOVuaD1oJGf"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "try:\n",
    "  import torch\n",
    "except ImportError:\n",
    "  !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "  import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSPoTlJupTMQ"
   },
   "outputs": [],
   "source": [
    "# Install PyG\n",
    "try:\n",
    "  import torch_geometric\n",
    "except ImportError:\n",
    "  !pip3 install torch_geometric\n",
    "  import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXVVqRjT0CHr"
   },
   "outputs": [],
   "source": [
    "# Clone and/or import gca-rom\n",
    "import sys\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/Fra-Sala/gnn_time.git\n",
    "    sys.path.append('./gnn_time/gca_time')\n",
    "else:\n",
    "    sys.path.append('./..')\n",
    "    \n",
    "from gca_time import network, pde, loader, plotting, preprocessing, training, initialization, testing, error, gui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBjDa3kg2gyX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvQWQQD274v"
   },
   "source": [
    "# Define PDE problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1sNbNWi2x5J",
    "outputId": "d09fec1b-1775-4c8f-b411-f8363d0cfb29"
   },
   "outputs": [],
   "source": [
    "problem_name, variable, mu_space,n_param = pde.problem(12)\n",
    "params = mu_space[0]\n",
    "time = mu_space[1]\n",
    "print(\"\\nProblem: \", problem_name)\n",
    "print(\"Variable: \", variable)\n",
    "print(\"Simulations: \", n_param)\n",
    "argv = gui.hyperparameters_selection(problem_name, variable, n_param)\n",
    "\n",
    "# Overwrite some selections\n",
    "argv[5] = 70  # 70% of the space parameter is used for training\n",
    "argv[8] = 10  # Dimension of latent state\n",
    "\n",
    "HyperParams = network.HyperParams(argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgphDqaw3Dvk"
   },
   "source": [
    "# Initialize device and set reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLoNgZkI257l",
    "outputId": "c275f8c8-ea0d-4476-d345-d361a3bdf03a"
   },
   "outputs": [],
   "source": [
    "device = initialization.set_device()\n",
    "initialization.set_reproducibility(HyperParams)\n",
    "initialization.set_path(HyperParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbCmXQ4I3IAv"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgCWJRAm3CuH",
    "outputId": "154681b3-5ad7-48f8-fe15-0ed7af1c094b"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    dataset_dir = '/content/gnn_time/gca_time/dataset/'+problem_name+'_unstructured.mat'\n",
    "else:\n",
    "    dataset_dir = '../dataset/'+problem_name+'_unstructured.mat'\n",
    "       \n",
    "dataset = loader.LoadDataset(dataset_dir, variable, dim_velocity=2)\n",
    "def delete_initial_condition(dataset, dim=2):\n",
    "    if dim == 1:\n",
    "        dataset.U = np.delete(dataset.U, np.s_[::10], 1)\n",
    "    elif dim == 2:\n",
    "        dataset.VX = np.delete(dataset.VX, np.s_[::10], 1)\n",
    "        dataset.VY = np.delete(dataset.VY, np.s_[::10], 1)\n",
    "    else:\n",
    "        print(\"Invalid dimension. Please enter 1 or 2.\")\n",
    "    return dataset\n",
    "\n",
    "dataset = delete_initial_condition(dataset, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrink dataset (debugging/define a rate for the time extrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim2keep = 20 # not greater than 20, in total (train and test, before application of train_rate)\n",
    "num_snap2keep = 7 # # not greater than 9\n",
    "# Note that setting num_snap2keep < 9 allows for time extrapolation: take the model trained on 7 snaps\n",
    "# then change num_snap2keep to 9 and run the notebook again\n",
    "\n",
    "def shrink_dataset(dataset, params, time, num_sim, num_snap_per_sim, dim=2):\n",
    "    new_time = time[:num_snap_per_sim+1]\n",
    "    new_params = params[:num_sim]\n",
    "    \n",
    "    if dim == 1:\n",
    "        new_U = []\n",
    "        new_XX = []\n",
    "        new_YY = []\n",
    "        for i in range(num_sim):\n",
    "            start = i * (len(time) - 1)\n",
    "            end = start + num_snap_per_sim\n",
    "            new_U.append(dataset.U[:, start:end])\n",
    "            new_XX.append(dataset.xx[:, start:end])\n",
    "            new_YY.append(dataset.yy[:, start:end])\n",
    "        new_U = np.concatenate(new_U, axis=1)\n",
    "        new_XX = np.concatenate(new_XX, axis=1)\n",
    "        new_YY = np.concatenate(new_YY, axis=1)\n",
    "\n",
    "        return new_U, new_XX, new_time, new_params\n",
    "    elif dim == 2:\n",
    "        new_VX = []\n",
    "        new_VY = []\n",
    "        new_XX = []\n",
    "        new_YY = []\n",
    "        for i in range(num_sim):\n",
    "            start = i * (len(time) - 1)\n",
    "            end = start + num_snap_per_sim\n",
    "            new_VX.append(dataset.VX[:, start:end])\n",
    "            new_VY.append(dataset.VY[:, start:end])\n",
    "            new_XX.append(dataset.xx[:, start:end])\n",
    "            new_YY.append(dataset.yy[:, start:end])\n",
    "        new_VX = np.concatenate(new_VX, axis=1)\n",
    "        new_VY = np.concatenate(new_VY, axis=1)\n",
    "        new_XX = np.concatenate(new_XX, axis=1)\n",
    "        new_YY = np.concatenate(new_YY, axis=1)\n",
    "    \n",
    "        return torch.tensor(new_VX), torch.tensor(new_VY), torch.tensor(new_XX), torch.tensor(new_YY), new_time, new_params\n",
    "\n",
    "dataset.VX, dataset.VY, dataset.xx, dataset.yy, time, params = shrink_dataset(dataset, params, time, num_sim2keep, num_snap2keep, dim=2)\n",
    "\n",
    "\n",
    "time = torch.from_numpy(time)\n",
    "\n",
    "print(\"Number of simulations (series of snaps):\", len(params))\n",
    "print(\"Number of instants of time (initial time excluded):\", len(time)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_loader, train_loader, test_loader, \\\n",
    "    val_loader, scaler_all, scaler_test, xyz, VAR_all, VAR_test, \\\n",
    "        train_trajectories, test_trajectories, params_train, params_test = preprocessing.graphs_dataset(dataset, HyperParams, params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NReTyPBUMzy0"
   },
   "source": [
    "# Define the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lW5gsJNl3K7_"
   },
   "outputs": [],
   "source": [
    "model_decoder = network.Net(HyperParams)\n",
    "model_dyn = network.DynNet(HyperParams)\n",
    "model_decoder = model_decoder.to(device)\n",
    "model_dyn = model_dyn.to(device)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model_dyn.parameters()},\n",
    "    {'params': model_decoder.parameters()}\n",
    "], lr=HyperParams.learning_rate,  weight_decay=HyperParams.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=HyperParams.miles, gamma=HyperParams.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpl8zN4eXRaF"
   },
   "source": [
    "# Train or load a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BPwYDBKXRru",
    "outputId": "7ab59192-e7d5-4f90-8090-d2dd9fceb427"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_decoder.load_state_dict(torch.load(HyperParams.net_dir+HyperParams.net_name+HyperParams.net_run+'_decoder.pt', map_location=torch.device('cpu')))\n",
    "    model_dyn.load_state_dict(torch.load(HyperParams.net_dir+HyperParams.net_name+HyperParams.net_run+'_dyn.pt', map_location=torch.device('cpu')))\n",
    "    print('Loading saved network')\n",
    "except FileNotFoundError:\n",
    "    print('Training network')\n",
    "    training.train(model_decoder, model_dyn, optimizer, device, scheduler, train_loader, test_loader, HyperParams, params_train, params_test, time)\n",
    "plotting.plot_loss(HyperParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hKW8WLhNuJB"
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Fgnj-NzNxDs",
    "outputId": "15080ae0-c39a-47c7-fd7e-0d056ad7b929"
   },
   "outputs": [],
   "source": [
    "model_decoder.to(\"cpu\")\n",
    "model_dyn.to(\"cpu\")\n",
    "results, latents = testing.evaluate(VAR_all, model_decoder, model_dyn, graph_loader, params, time, HyperParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSJLj7rMN3iE"
   },
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = np.repeat(params, len(time)-1, axis=0)\n",
    "TIMES = np.tile(time[1:], params.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time extrapolation capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider only parameters that were used for training, and we see how the model predicts the evolution of the system\n",
    "# over unseen instants of time. The marker changes when moving from training to test data in time.\n",
    "# If you want to see how the model behaves in time extrapolation, train the network on num_snap2keep <9. Then, set num_snap2keep = 9 and run the notebook.\n",
    "# but do NOT change the number of num_sim2keep, otherwise you will see plotted training data that the network has never seen.\n",
    "# This is because the notebook is not yet structured to deal with both time extrapolation and parameter extrapolation.\n",
    "plotting.plot_time_extrapolation(results, scaler_all, HyperParams, dataset, params_train, time, n_train_instants = 3 )\n",
    "\n",
    "# Blue dots denote training data, red crosses denote testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance over time and parameter space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_error(results, dataset, scaler_all, HyperParams, params, PARAMS, time[1:], TIMES, train_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predicted and error fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VwIkAWi4NzsF",
    "outputId": "05f2e3b9-45a0-4da3-8b3d-ba322d03dfb1"
   },
   "outputs": [],
   "source": [
    "# If you want to see how the model behaves in time extrapolation, train the network on num_snap2keep <9. Then, set num_snap2keep = 9 and run the notebook.\n",
    "snapshots = test_trajectories[:10]\n",
    "\n",
    "time.detach().numpy()\n",
    "for SNAP in snapshots:\n",
    "    plotting.plot_latent(SNAP, latents, params, time, HyperParams)\n",
    "    plotting.plot_fields(SNAP, results, scaler_all, HyperParams, dataset, PARAMS, TIMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiaGsslJN8AH"
   },
   "source": [
    "# Print the errors on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1BkkSEBN7K5",
    "outputId": "ebea2323-0ddb-4a92-b1c4-b8c8342f4b93"
   },
   "outputs": [],
   "source": [
    "# error_abs, norm = error.compute_error(results_test, VAR_test, scaler_test, HyperParams)\n",
    "# error.print_error(error_abs, norm, vars)\n",
    "# error.save_error(error_abs, norm, HyperParams, vars)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyML8rllKyOnNo3bcpAT49WU",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
