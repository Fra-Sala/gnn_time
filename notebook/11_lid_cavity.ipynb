{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github.com/Fra-Sala/gnn_time/blob/main/notebook/11_lid_cavity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CtOVuaD1oJGf"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "try:\n",
    "  import torch\n",
    "except ImportError:\n",
    "  !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "  import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NSPoTlJupTMQ"
   },
   "outputs": [],
   "source": [
    "# Install PyG\n",
    "try:\n",
    "  import torch_geometric\n",
    "except ImportError:\n",
    "  !pip3 install torch_geometric\n",
    "  import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq ipdb\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rXVVqRjT0CHr"
   },
   "outputs": [],
   "source": [
    "# Clone and import gca-rom\n",
    "#!git clone https://github.com/Fra-Sala/gnn_time.git\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    sys.path.append('gnn_time')\n",
    "else:\n",
    "    sys.path.append('./..')\n",
    "    \n",
    "from gca_rom import network, pde, loader, plotting, preprocessing, training, initialization, testing, error, gui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sBjDa3kg2gyX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvQWQQD274v"
   },
   "source": [
    "# Define PDE problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1sNbNWi2x5J",
    "outputId": "d09fec1b-1775-4c8f-b411-f8363d0cfb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem:  lid_cavity\n",
      "Variable:  U\n",
      "Parameters:  2\n"
     ]
    }
   ],
   "source": [
    "problem_name, variable, mu_space, n_param = pde.problem(11)\n",
    "print(\"\\nProblem: \", problem_name)\n",
    "print(\"Variable: \", variable)\n",
    "print(\"Parameters: \", n_param)\n",
    "argv = gui.hyperparameters_selection(problem_name, variable, n_param)\n",
    "\n",
    "# Change the training rate \"manually\"\n",
    "argv[5] = 70  \n",
    "# Sanity check: learn only the \"identity\" map\n",
    "#argv[9] = 0.0\n",
    "\n",
    "HyperParams = network.HyperParams(argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgphDqaw3Dvk"
   },
   "source": [
    "# Initialize device and set reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLoNgZkI257l",
    "outputId": "c275f8c8-ea0d-4476-d345-d361a3bdf03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = initialization.set_device()\n",
    "initialization.set_reproducibility(HyperParams)\n",
    "initialization.set_path(HyperParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbCmXQ4I3IAv"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgCWJRAm3CuH",
    "outputId": "154681b3-5ad7-48f8-fe15-0ed7af1c094b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes processed:  15681\n",
      "Number of graphs processed:  30\n",
      "Length of train dataset:  21\n",
      "Length of test dataset:  9\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    dataset_dir = '/content/gnn_time/dataset/'+problem_name+'_unstructured.mat'\n",
    "else:\n",
    "    dataset_dir = '../dataset/'+problem_name+'_unstructured.mat'\n",
    "    \n",
    "dataset = loader.LoadDataset(dataset_dir, variable)\n",
    "\n",
    "graph_loader, train_loader, test_loader, \\\n",
    "    val_loader, scaler_all, scaler_test, xyz, VAR_all, VAR_test, \\\n",
    "        train_trajectories, test_trajectories = preprocessing.graphs_dataset(dataset, HyperParams)\n",
    "\n",
    "#params = torch.tensor(np.array(list(product(*mu_space))))\n",
    "\n",
    "\"\"\" Non-causal approach \"\"\"\n",
    "\n",
    "time = mu_space.pop()\n",
    "n_sim = int(len(mu_space[0])/len(time))\n",
    "time_tile = np.tile(time, n_sim)\n",
    "print(len(mu_space[0])/len(time))\n",
    "params = []\n",
    "for i in range(len(mu_space[0])):\n",
    "        new_set_params = np.concatenate(([mu_space[0][i]], [time_tile[i]]), axis = 0)\n",
    "        params.append(new_set_params)\n",
    "\n",
    "\"\"\" Fourier approach \"\"\"\n",
    "# time = mu_space.pop()\n",
    "# time_tile = np.tile(time, len(mu_space[0])/len(time))\n",
    "# params = []\n",
    "# for i in range(len(mu_space[0])):\n",
    "#     set_coeff = [arr[i] for arr in mu_space]\n",
    "#     for j in range(len(time)):\n",
    "#         new_set = np.concatenate((set_coeff, [time[j]]), axis = 0)\n",
    "#         params.append(new_set)\n",
    "\n",
    "params = torch.tensor(params)\n",
    "params = params.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NReTyPBUMzy0"
   },
   "source": [
    "# Define the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lW5gsJNl3K7_"
   },
   "outputs": [],
   "source": [
    "model = network.Net(HyperParams)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=HyperParams.learning_rate, weight_decay=HyperParams.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=HyperParams.miles, gamma=HyperParams.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpl8zN4eXRaF"
   },
   "source": [
    "# Train or load a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BPwYDBKXRru",
    "outputId": "7ab59192-e7d5-4f90-8090-d2dd9fceb427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–Œ| 26/50 [00:35<00:33,  1.38s/it, Loss(training)=0.832, Loss(validation)=1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(HyperParams\u001b[38;5;241m.\u001b[39mnet_dir\u001b[38;5;241m+\u001b[39mHyperParams\u001b[38;5;241m.\u001b[39mnet_name\u001b[38;5;241m+\u001b[39mHyperParams\u001b[38;5;241m.\u001b[39mnet_run\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading saved network\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './lid_cavity/_standard/U_lid_cavity_lmap10.0_btt25_seed10_lv4_hc2_nd50_ffn200_skip1_lr0.001_sc4_rate70/lid_cavity_standard.pt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining network\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain(model, optimizer, device, scheduler, params, train_loader, test_loader, train_trajectories, test_trajectories, HyperParams)\n",
      "File \u001b[0;32m~/Desktop/SEMESTER_PROJECT_2/gnn_time/notebook/./../gca_rom/training.py:47\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, device, scheduler, params, train_loader, test_loader, train_trajectories, test_trajectories, HyperParams)\u001b[0m\n\u001b[1;32m     45\u001b[0m loss_train_map \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(z_estimation, z, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m loss_train_mse \u001b[38;5;241m+\u001b[39m HyperParams\u001b[38;5;241m.\u001b[39mlambda_map \u001b[38;5;241m*\u001b[39m loss_train_map\n\u001b[0;32m---> 47\u001b[0m loss_train\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m sum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_train\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(HyperParams.net_dir+HyperParams.net_name+HyperParams.net_run+'.pt', map_location=torch.device('cpu')))\n",
    "    print('Loading saved network')\n",
    "except FileNotFoundError:\n",
    "    print('Training network')\n",
    "    training.train(model, optimizer, device, scheduler, params, train_loader, test_loader, train_trajectories, test_trajectories, HyperParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hKW8WLhNuJB"
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Fgnj-NzNxDs",
    "outputId": "15080ae0-c39a-47c7-fd7e-0d056ad7b929"
   },
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "params = params.to(\"cpu\")\n",
    "vars = \"GCA-ROM\"\n",
    "results, latents_map, latents_gca = testing.evaluate(VAR_all, model, graph_loader, params, HyperParams, range(params.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSJLj7rMN3iE"
   },
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VwIkAWi4NzsF",
    "outputId": "05f2e3b9-45a0-4da3-8b3d-ba322d03dfb1"
   },
   "outputs": [],
   "source": [
    "plotting.plot_loss(HyperParams)\n",
    "plotting.plot_latent(HyperParams, latents_map, latents_gca)\n",
    "#plotting.plot_error(results, VAR_all, scaler_all, HyperParams, mu_space, params, train_trajectories, vars)\n",
    "\n",
    "N = 5\n",
    "snapshots = np.arange(params.shape[0]).tolist()\n",
    "np.random.shuffle(snapshots)\n",
    "for SNAP in snapshots[0:N]:\n",
    "    plotting.plot_fields(SNAP, results, scaler_all, HyperParams, dataset, xyz, params)\n",
    "    plotting.plot_error_fields(SNAP, results, VAR_all, scaler_all, HyperParams, dataset, xyz, params)\n",
    "\n",
    "results_test, _, _ = testing.evaluate(VAR_test, model, val_loader, params, HyperParams, test_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiaGsslJN8AH"
   },
   "source": [
    "# Print the errors on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1BkkSEBN7K5",
    "outputId": "ebea2323-0ddb-4a92-b1c4-b8c8342f4b93"
   },
   "outputs": [],
   "source": [
    "error_abs, norm = error.compute_error(results_test, VAR_test, scaler_test, HyperParams)\n",
    "error.print_error(error_abs, norm, vars)\n",
    "error.save_error(error_abs, norm, HyperParams, vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r /content/lid_cavity.zip /content/lid_cavity"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyML8rllKyOnNo3bcpAT49WU",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
